{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment\n",
    "\n",
    "This notebook and package was created in `Python 3.10.6`.\n",
    "<br>\n",
    "It is highly recommended to create a new virtual environment in `3.10.6` before executing the following setup.\n",
    "\n",
    "Run the following code in your terminal to install required libraries & dependencies:\n",
    "```\n",
    "cd {your/file/path}/corpy-assessment\n",
    "make install\n",
    "```\n",
    "where `{your/file/path}` is the location where you saved the `corpy-assessment` folder.\n",
    "\n",
    "## Checking the setup\n",
    "\n",
    "Once setup completes, run in the terminal:\n",
    "```\n",
    "pip list | grep corpy\n",
    "```\n",
    "<br>\n",
    "\n",
    "If the terminal shows the following, then setup has been successful.\n",
    "```\n",
    "corpy       0.0.1\n",
    "```\n",
    "<br>\n",
    "Continue with the rest of the notebook once setup is complete."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpy.get_data.get_data import data_download\n",
    "\n",
    "data_download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import official packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# import custom package\n",
    "from corpy.ml_logic.data import load_data\n",
    "from corpy.ml_logic.model import create_encoder, create_decoder, AutoEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size\n",
    "batch_size = 32\n",
    "\n",
    "# set resized image size (pixels)\n",
    "img_size = 128\n",
    "\n",
    "# load data augmented training data (250 original + 750 augmented images)\n",
    "ds_train = load_data(batch_size, img_size, 'train')\n",
    "\n",
    "# load test data (180 images)\n",
    "ds_test = load_data(batch_size, img_size, 'test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Encoder & Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dimension of latent layer\n",
    "latent_dim = 128\n",
    "\n",
    "# build encoder & decoder\n",
    "encoder, shape = create_encoder(img_size, latent_dim)\n",
    "decoder = create_decoder(shape, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check encoder\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check decoder\n",
    "decoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build & compile AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set learning rate decay\n",
    "lr_decay = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.2,\n",
    "    patience=10,\n",
    "    min_lr=0.00001,\n",
    "    cooldown=100,\n",
    "    verbose=1)\n",
    "\n",
    "# compile AutoEncoder\n",
    "ae = AutoEncoder(encoder, decoder)\n",
    "ae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train AutoEncoder\n",
    "\n",
    "Uncomment the next cell to train AutoEncoder.\n",
    "<br>\n",
    "To skip training, a pre-trained model can be loaded in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = ae.fit(ds_train, epochs=250, verbose=1, callbacks=[lr_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip training and load pre-trained weights\n",
    "ae.build(input_shape=(None,128,128,3))\n",
    "ae.load_weights('trained/ae_mse_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training history\n",
    "mse_history = pd.read_csv('trained/ae_mse_history.csv')\n",
    "mse_history.loc[:, ['loss']].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test images & predictions\n",
    "original = []\n",
    "reconstructed = []\n",
    "for batch in range(len(list(ds_test))):\n",
    "\tinput = list(ds_test)[batch]\n",
    "\toutput = ae(input)\n",
    "\toriginal.extend(input)\n",
    "\treconstructed.extend(list(output))\n",
    "\n",
    "print(f\"[INFO] number of test images: {len(original)}\")\n",
    "\n",
    "\n",
    "# calculate mse between original and reconstructed images\n",
    "error = []\n",
    "for (o, r) in zip(original, reconstructed):\n",
    "\tmse = np.mean((o - r)**2)\n",
    "\terror.append(mse)\n",
    "\n",
    "\n",
    "# compute the q-th quantile of the mses to be threshold to identify anomalies\n",
    "# any reconstructed image with mse > threshold will be defined as an anomaly\n",
    "thresh = np.quantile(error, 0.90)\n",
    "print(f\"[INFO] mse threshold: {thresh}\")\n",
    "\n",
    "\n",
    "# count anomalies found\n",
    "idxs = np.where(np.array(error) >= thresh)[0]\n",
    "print(f\"[INFO] {len(idxs)} anomalies found\")\n",
    "\n",
    "# retrieve original & reconstructed images where mse > threshold\n",
    "outputs = None\n",
    "for i in idxs:\n",
    "\torig = original[i]\n",
    "\trecon = reconstructed[i]\n",
    "\tdiff = (orig - recon) * 2\n",
    "\t\n",
    "    # stack the original, reconstructed, & difference mask images side-by-side\n",
    "\toutput = np.hstack([orig, recon, diff])\n",
    "\n",
    "    # if output is the first image, initialize\n",
    "\tif outputs is None:\n",
    "\t\toutputs = output\n",
    "\n",
    "    # otherwise, vertically stack the output to previous outputs\n",
    "\telse:\n",
    "\t\toutputs = np.vstack([outputs, output])\n",
    "\n",
    "# show the output\n",
    "plt.figure(figsize=(12, 50))\n",
    "plt.imshow(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20907d215214c6d72cb244ebc8bd283ce97b32b6cc8bdf0dcd140f83c1e88dbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
